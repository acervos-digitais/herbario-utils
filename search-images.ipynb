{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Images by other Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import makedirs, path\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Crop Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from models.CLIP import Clip\n",
    "from models.Owlv2 import Owlv2Embedding as Owlv2\n",
    "from models.SigLip2 import SigLip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_IMGS_PATH = \"../../imgs/arts/crops\"\n",
    "CROP_EMBED_PATH = \"./metadata/json/art-crops/embeddings\"\n",
    "\n",
    "# CROP_IMGS_PATH = \"../../imgs/palms/crops\"\n",
    "# CROP_EMBED_PATH = \"./metadata/json/palm-crops/embeddings\"\n",
    "\n",
    "makedirs(CROP_EMBED_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Clip()\n",
    "model_name = type(model).__name__.lower().replace(\"embedding\", \"\")\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fnames = sorted([fn for fn in listdir(CROP_IMGS_PATH) if fn.endswith(\".jpg\")])\n",
    "len(crop_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,fname in enumerate(crop_fnames):\n",
    "  if idx % 100 == 0:\n",
    "    print(f\"{idx} / {len(crop_fnames)}\")\n",
    "\n",
    "  qid = fname.replace(\".jpg\", \"\")\n",
    "  image_path = path.join(CROP_IMGS_PATH, fname)\n",
    "  embedding_path = path.join(CROP_EMBED_PATH, f\"{qid}.json\")\n",
    "\n",
    "  embeds = {}\n",
    "  if path.isfile(embedding_path):\n",
    "    with open(embedding_path, \"r\") as ifp:\n",
    "      embeds = json.load(ifp)[qid]\n",
    "\n",
    "  if model_name in embeds:\n",
    "    continue\n",
    "\n",
    "  img = PImage.open(image_path)\n",
    "  embeds[model_name] = [round(v, 8) for v in model.get_embedding(img).tolist()]\n",
    "  embedding_data = { qid: embeds }\n",
    "\n",
    "  with open(embedding_path, \"w\") as ofp:\n",
    "    json.dump(embedding_data, ofp, separators=(\",\",\":\"), sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PALM_IMGS_PATH = \"../../imgs/palms/crops\"\n",
    "PALM_EMBED_PATH = \"./metadata/json/palm-crops/embeddings\"\n",
    "\n",
    "model = \"siglip2\"\n",
    "\n",
    "target = \"caryota-rumphiana_001\"\n",
    "\n",
    "target_embedding_path = path.join(PALM_EMBED_PATH, f\"{target}.json\")\n",
    "with open(target_embedding_path, \"r\") as ifp:\n",
    "  target_embedding = np.array([json.load(ifp)[target][model]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_fnames = sorted([fn for fn in listdir(PALM_EMBED_PATH) if fn.endswith(\".json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeds = []\n",
    "all_ids = []\n",
    "\n",
    "for fname in embed_fnames:\n",
    "  qid = fname.replace(\".json\", \"\")\n",
    "  embedding_path = path.join(PALM_EMBED_PATH, fname)\n",
    "  img_path = path.join(PALM_IMGS_PATH, f\"{qid}.jpg\")\n",
    "\n",
    "  with open(embedding_path, \"r\") as ifp:\n",
    "    all_embeds.append(json.load(ifp)[qid][model])\n",
    "    all_ids.append(qid)\n",
    "\n",
    "all_ids = np.array(all_ids)\n",
    "all_embeds = np.array(all_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = cosine_distances(all_embeds, target_embedding).reshape(-1)\n",
    "euc_dists = euclidean_distances(all_embeds, target_embedding).reshape(-1)\n",
    "\n",
    "cos_dist_idx = np.argsort(cos_dists)\n",
    "euc_dist_idx = np.argsort(euc_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids[cos_dist_idx[:3]], all_ids[euc_dist_idx[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by Image\n",
    "\n",
    "Note:\n",
    "- Owlv2 doesn't really work\n",
    "- Clip is ok\n",
    "- SigLip2 is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "from PIL import Image as PImage, ImageOps as PImageOps, ImageDraw as PImageDraw\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PALM_IMGS_PATH = \"../../imgs/palms/crops\"\n",
    "PALM_EMBED_PATH = \"./metadata/json/palm-crops/embeddings\"\n",
    "\n",
    "model = \"siglip2\"\n",
    "\n",
    "target = \"ceroxylon_000\"\n",
    "\n",
    "target_embedding_path = path.join(PALM_EMBED_PATH, f\"{target}.json\")\n",
    "with open(target_embedding_path, \"r\") as ifp:\n",
    "  target_embedding = np.array([json.load(ifp)[target][model]])\n",
    "\n",
    "tgt_img = PImage.open(path.join(PALM_IMGS_PATH, f\"{target}.jpg\"))\n",
    "display(tgt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_IMGS_PATH = \"../../imgs/arts/crops\"\n",
    "CROP_EMBED_PATH = \"./metadata/json/art-crops/embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_fnames = sorted([fn for fn in listdir(CROP_EMBED_PATH) if fn.endswith(\".json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeds = []\n",
    "all_ids = []\n",
    "\n",
    "for fname in embed_fnames:\n",
    "  qid = fname.replace(\".json\", \"\")\n",
    "  embedding_path = path.join(CROP_EMBED_PATH, fname)\n",
    "  img_path = path.join(CROP_IMGS_PATH, f\"{qid}.jpg\")\n",
    "\n",
    "  with open(embedding_path, \"r\") as ifp:\n",
    "    all_embeds.append(json.load(ifp)[qid][model])\n",
    "    all_ids.append(qid)\n",
    "\n",
    "all_ids = np.array(all_ids)\n",
    "all_embeds = np.array(all_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dists = cosine_distances(all_embeds, target_embedding).reshape(-1)\n",
    "euc_dists = euclidean_distances(all_embeds, target_embedding).reshape(-1)\n",
    "\n",
    "cos_dist_idx = np.argsort(cos_dists)\n",
    "euc_dist_idx = np.argsort(euc_dists)\n",
    "\n",
    "all_ids[cos_dist_idx[:3]], all_ids[euc_dist_idx[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in euc_dist_idx[:8]:\n",
    "  id = all_ids[idx]\n",
    "  pimg = PImage.open(path.join(CROP_IMGS_PATH, f\"{id}.jpg\"))\n",
    "  pimg.thumbnail((200,200))\n",
    "  print(id)\n",
    "  display(pimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cos_dist_idx[:8]:\n",
    "  id = all_ids[idx]\n",
    "  pimg = PImage.open(path.join(CROP_IMGS_PATH, f\"{id}.jpg\"))\n",
    "  pimg.thumbnail((200,200))\n",
    "  print(id)\n",
    "  display(pimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Image Crop by Objectness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "\n",
    "from models.Owlv2 import Owlv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Owlv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"borassus_000\"\n",
    "img = PImage.open(f\"../../imgs/palms/00/{fname}.jpg\")\n",
    "img.thumbnail((900,900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_boxes = model.get_objectness_boxes(img, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimg = img.copy()\n",
    "draw = PImageDraw.Draw(dimg)\n",
    "\n",
    "for x1, y1, x2, y2 in crop_boxes:\n",
    "  draw.rectangle(xy=((x1, y1), (x2, y2)), outline=\"red\")\n",
    "\n",
    "display(dimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SigLip2 (embedding)\n",
    "\n",
    "Large patch 16x16:\n",
    "- https://huggingface.co/google/siglip2-large-patch16-384\n",
    "- https://huggingface.co/google/siglip2-large-patch16-512\n",
    "\n",
    "Giant 16x16:\n",
    "- https://huggingface.co/google/siglip2-giant-opt-patch16-256\n",
    "- https://huggingface.co/google/siglip2-giant-opt-patch16-384\n",
    "\n",
    "\n",
    "## Owl2 (zero-shot detection)\n",
    "- https://huggingface.co/google/owlv2-base-patch16\n",
    "- https://huggingface.co/google/owlv2-large-patch14\n",
    "- https://huggingface.co/google/owlv2-large-patch14-ensemble\n",
    "\n",
    "- [Niels' Tutorial](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/OWLv2/Zero_and_one_shot_object_detection_with_OWLv2.ipynb)\n",
    "\n",
    "#### Results from experiments\n",
    "- Use larger images and smaller models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
