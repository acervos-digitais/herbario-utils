{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from Museum import Museum\n",
    "from params.collections import MUSEUMS\n",
    "\n",
    "PREFIX = \"20250705\"\n",
    "DATA_DIR = \"./metadata/json\"\n",
    "DATA_FILE = f\"{DATA_DIR}/{PREFIX}_processed.json\"\n",
    "CLUSTER_FILE = f\"{DATA_DIR}/{PREFIX}_clusters.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearClass:\n",
    "  def __init__(self, min_year, max_year, gran):\n",
    "    def year2class(year):\n",
    "      if year < min_year:\n",
    "        return 0\n",
    "      elif year >= max_year:\n",
    "        return int((max_year - min_year) / gran) + 1\n",
    "      else:\n",
    "        return int((year - min_year) / gran) + 1\n",
    "\n",
    "    def class2year(cls):\n",
    "      if cls == 0 or cls == int((max_year - min_year) / gran) + 1:\n",
    "        return 9999\n",
    "        return min_year - 1\n",
    "      else:\n",
    "        return ((cls - 1) * gran) + min_year\n",
    "\n",
    "    self.year2class = year2class\n",
    "    self.class2year = class2year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mYC = YearClass(1700, 2000, 50)\n",
    "\n",
    "embedding_data = Museum.combine_all_data(MUSEUMS, \"embeddings\")\n",
    "\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as ifp:\n",
    "  all_data = json.load(ifp)\n",
    "\n",
    "with open(CLUSTER_FILE, \"r\", encoding=\"utf-8\") as ifp:\n",
    "  cluster_data_all = json.load(ifp)\n",
    "  cluster_data = cluster_data_all[\"8\"][\"images\"]\n",
    "\n",
    "class_data = []\n",
    "\n",
    "for id in all_data.keys():\n",
    "  if all_data[id][\"year\"] < 2030:\n",
    "    class_data.append({\n",
    "      \"id\": str(all_data[id][\"id\"]),\n",
    "      \"year\": all_data[id][\"year\"],\n",
    "      \"cluster\": cluster_data[id][\"cluster\"],\n",
    "      \"class\": mYC.year2class(all_data[id][\"year\"]),\n",
    "      \"embedding\": embedding_data[id][\"siglip2\"]\n",
    "    })\n",
    "\n",
    "class_data_train, class_data_test = train_test_split(class_data, test_size=0.25, random_state=101010)\n",
    "\n",
    "classes_train = np.array([x[\"class\"] for x in class_data_train])\n",
    "classes_test = np.array([x[\"class\"] for x in class_data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageClassify:\n",
    "  @classmethod\n",
    "  def top_k_accuracy(cls, labels, preds, k=1):\n",
    "    corrects = [1 for l,ps in zip(labels, preds) if l in ps[:k]]\n",
    "    return len(corrects) / len(labels)\n",
    "\n",
    "  @classmethod\n",
    "  def dist_accuracy(cls, labels, preds):\n",
    "    correct_idxs = []\n",
    "    wrong_idxs = []\n",
    "    for idx,pred in enumerate(preds):\n",
    "      if pred[0] == labels[idx]:\n",
    "        correct_idxs.append(idx)\n",
    "      else:\n",
    "        wrong_idxs.append(idx)\n",
    "\n",
    "    correct_dists = preds[correct_idxs][:, 1]\n",
    "    wrong_dists = preds[wrong_idxs][:, 1]\n",
    "\n",
    "    print(\"Correct:\", correct_dists.min(), correct_dists.max(), correct_dists.mean())\n",
    "    if len(wrong_dists) > 0:\n",
    "      print(\"Wrong:\", wrong_dists.min(), wrong_dists.max(), wrong_dists.mean())\n",
    "\n",
    "    plt.hist(correct_dists, bins=30)\n",
    "    plt.title(\"Correct\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(wrong_dists, bins=30)\n",
    "    plt.title(\"Wrong\")\n",
    "    plt.show()\n",
    "\n",
    "    return len(correct_idxs) / len(labels)\n",
    "\n",
    "  def __init__(self, n_averages):\n",
    "    self.n_averages = n_averages\n",
    "    self.average_centers = []\n",
    "    self.idx2class = []\n",
    "\n",
    "  def fit(self, data):\n",
    "    classes = np.array([x[\"class\"] for x in data])\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "\n",
    "    self.average_centers = []\n",
    "    self.idx2class = []\n",
    "\n",
    "    for mclass in np.sort(np.unique(classes)):\n",
    "      mclass_embs = embeddings[np.where(classes == mclass)]\n",
    "      mKMeans = KMeans(n_clusters=min(len(mclass_embs), self.n_averages), random_state=1010)\n",
    "      mKMeans.fit(mclass_embs)\n",
    "\n",
    "      for avg_val in mKMeans.cluster_centers_:\n",
    "        self.average_centers.append(avg_val)\n",
    "        self.idx2class.append(mclass)\n",
    "\n",
    "    self.average_centers = np.array(self.average_centers)\n",
    "    self.idx2class = np.array(self.idx2class)\n",
    "\n",
    "  def predict(self, data):\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "    dists = euclidean_distances(embeddings, self.average_centers)\n",
    "    return np.array([[self.idx2class[idx] for idx in ds.reshape(-1).argsort()] for ds in dists])\n",
    "\n",
    "  def predict_dist(self, data):\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "    dists = euclidean_distances(embeddings, self.average_centers)\n",
    "    classes_dists = np.array([[[self.idx2class[idx], ds[idx]] for idx in ds.reshape(-1).argsort()] for ds in dists])\n",
    "    return classes_dists[:, 0]\n",
    "\n",
    "\n",
    "class ClusterClassify:\n",
    "  def __init__(self, n_averages, n_clusters=8):\n",
    "    self.n_averages = n_averages\n",
    "    self.n_clusters = n_clusters\n",
    "    self.cluster_average_centers = []\n",
    "    self.idx2class = []\n",
    "\n",
    "  def fit(self, data):\n",
    "    clusters = np.array([x[\"cluster\"] for x in data])\n",
    "\n",
    "    self.cluster_average_centers = []\n",
    "    self.idx2class = []\n",
    "\n",
    "    for mcluster in np.sort(np.unique(clusters)):\n",
    "      cluster_data = np.array(data)[np.where(clusters == mcluster)]\n",
    "      cluster_classes = np.array([x[\"class\"] for x in cluster_data])\n",
    "      cluster_embeddings = np.array([x[\"embedding\"] for x in cluster_data])\n",
    "\n",
    "      for mclass in np.sort(np.unique(cluster_classes)):\n",
    "        mclass_embs = cluster_embeddings[np.where(cluster_classes == mclass)]\n",
    "        mKMeans = KMeans(n_clusters=min(len(mclass_embs), self.n_averages), random_state=1010)\n",
    "        mKMeans.fit(mclass_embs)\n",
    "\n",
    "        for avg_val in mKMeans.cluster_centers_:\n",
    "          self.cluster_average_centers.append(avg_val)\n",
    "          self.idx2class.append(mclass)\n",
    "\n",
    "    self.cluster_average_centers = np.array(self.cluster_average_centers)\n",
    "    self.idx2class = np.array(self.idx2class)\n",
    "\n",
    "  def predict(self, data):\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "    dists = euclidean_distances(embeddings, self.cluster_average_centers)\n",
    "    return np.array([[self.idx2class[idx] for idx in ds.reshape(-1).argsort()] for ds in dists])\n",
    "\n",
    "\n",
    "class SKClassify:\n",
    "  def fit(self, data):\n",
    "    classes = np.array([x[\"class\"] for x in data])\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "\n",
    "    if self.pca:\n",
    "      self.mCC.fit(self.pca.fit_transform(embeddings), classes)\n",
    "    else:\n",
    "      self.mCC.fit(embeddings, classes)\n",
    "\n",
    "  def predict(self, data):\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "\n",
    "    if self.pca:\n",
    "      return self.mCC.predict(self.pca.transform(embeddings))\n",
    "    else:\n",
    "      return self.mCC.predict(embeddings)\n",
    "\n",
    "  def predict_prob(self, data):\n",
    "    embeddings = np.array([x[\"embedding\"] for x in data])\n",
    "\n",
    "    if self.pca:\n",
    "      embeddings = self.pca.transform(embeddings)\n",
    "\n",
    "    probs = self.mCC.predict_proba(embeddings)\n",
    "    classes_probs = np.array([[[idx, ps[idx]] for idx in (-ps).reshape(-1).argsort()] for ps in probs])\n",
    "    return classes_probs[:, 0]\n",
    "\n",
    "class RFClassify(SKClassify):\n",
    "  def __init__(self, n_components=None):\n",
    "    self.mCC = RandomForestClassifier()\n",
    "    self.pca = PCA(n_components=n_components) if n_components else None\n",
    "\n",
    "class KNNClassify(SKClassify):\n",
    "  def __init__(self, n_neighbors=5, n_components=None):\n",
    "    self.mCC = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    self.pca = PCA(n_components=n_components) if n_components else None\n",
    "\n",
    "class SVClassify(SKClassify):\n",
    "  def __init__(self, C=1.0, probability=False, n_components=None):\n",
    "    self.mCC = SVC(C=C, probability=probability)\n",
    "    self.pca = PCA(n_components=n_components) if n_components else None\n",
    "\n",
    "class MLPClassify(SKClassify):\n",
    "  def __init__(self, n_components=None):\n",
    "    self.mCC = MLPClassifier(hidden_layer_sizes=(128))\n",
    "    self.pca = PCA(n_components=n_components) if n_components else None\n",
    "\n",
    "\n",
    "class TorchClassify:\n",
    "  def __init__(self, lr=1e-6, epochs=32):\n",
    "    self.learning_rate = lr\n",
    "    self.epochs = epochs\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def fit(self, data):\n",
    "    classes = Tensor([x[\"class\"] for x in data]).long()\n",
    "    embeddings = Tensor([x[\"embedding\"] for x in data])\n",
    "\n",
    "    self.model =  nn.Sequential(\n",
    "      nn.Dropout(0.35),\n",
    "      nn.Linear(embeddings.shape[1], embeddings.shape[1] // 2),\n",
    "      nn.BatchNorm1d(embeddings.shape[1] // 2),\n",
    "      nn.LayerNorm(embeddings.shape[1] // 2),\n",
    "      nn.ReLU(),\n",
    "\n",
    "      nn.Dropout(0.35),\n",
    "      nn.Linear(embeddings.shape[1] // 2, len(classes.unique())),\n",
    "    )\n",
    "\n",
    "    optim = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "\n",
    "    for e in range(self.epochs):\n",
    "      optim.zero_grad()\n",
    "      classes_pred = self.model(embeddings)\n",
    "      loss = self.loss_fn(classes_pred, classes)\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      if e % (self.epochs // 8) == 0:\n",
    "        print(f\"Epoch: {e} loss: {loss.item():.4f}\")\n",
    "\n",
    "  def predict(self, data):\n",
    "    embeddings = Tensor([x[\"embedding\"] for x in data])\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "      class_pred = self.model(embeddings).argmax(dim=1)\n",
    "    return [l.item() for l in class_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = AverageClassify(24)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train[:, 0])}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test[:, 0])}\")\n",
    "print()\n",
    "print(f\"train: {AverageClassify.top_k_accuracy(classes_train, preds_train, 2)}\")\n",
    "print(f\"test: {AverageClassify.top_k_accuracy(classes_test, preds_test, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = AverageClassify(24)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict_dist(class_data_train)\n",
    "preds_test = mCC.predict_dist(class_data_test)\n",
    "\n",
    "print(f\"train: {AverageClassify.dist_accuracy(classes_train, preds_train)}\")\n",
    "print(f\"test: {AverageClassify.dist_accuracy(classes_test, preds_test)}\")\n",
    "\n",
    "# thold: <10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = ClusterClassify(20)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train[:, 0])}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test[:, 0])}\")\n",
    "print()\n",
    "print(f\"train: {AverageClassify.top_k_accuracy(classes_train, preds_train, 2)}\")\n",
    "print(f\"test: {AverageClassify.top_k_accuracy(classes_test, preds_test, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = KNNClassify(7)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train)}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = KNNClassify(7)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict_prob(class_data_train)\n",
    "preds_test = mCC.predict_prob(class_data_test)\n",
    "\n",
    "print(f\"train: {AverageClassify.dist_accuracy(classes_train, preds_train)}\")\n",
    "print(f\"test: {AverageClassify.dist_accuracy(classes_test, preds_test)}\")\n",
    "\n",
    "# thold: >0.8 (correct mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = RFClassify(32)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train)}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = RFClassify(32)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict_prob(class_data_train)\n",
    "preds_test = mCC.predict_prob(class_data_test)\n",
    "\n",
    "print(f\"train: {AverageClassify.dist_accuracy(classes_train, preds_train)}\")\n",
    "print(f\"test: {AverageClassify.dist_accuracy(classes_test, preds_test)}\")\n",
    "\n",
    "# thold: >0.65 (correct mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = SVClassify(C=8.0, n_components=128)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train)}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = SVClassify(C=8.0, probability=True, n_components=128)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict_prob(class_data_train)\n",
    "preds_test = mCC.predict_prob(class_data_test)\n",
    "\n",
    "print(f\"train: {AverageClassify.dist_accuracy(classes_train, preds_train)}\")\n",
    "print(f\"test: {AverageClassify.dist_accuracy(classes_test, preds_test)}\")\n",
    "\n",
    "# thold: >0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = MLPClassify(128)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train)}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = MLPClassify(128)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict_prob(class_data_train)\n",
    "preds_test = mCC.predict_prob(class_data_test)\n",
    "\n",
    "print(f\"train: {AverageClassify.dist_accuracy(classes_train, preds_train)}\")\n",
    "print(f\"test: {AverageClassify.dist_accuracy(classes_test, preds_test)}\")\n",
    "\n",
    "# thold: >????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCC = TorchClassify(lr=1e-1, epochs=192)\n",
    "mCC.fit(class_data_train)\n",
    "\n",
    "preds_train = mCC.predict(class_data_train)\n",
    "preds_test = mCC.predict(class_data_test)\n",
    "\n",
    "print(f\"train: {accuracy_score(classes_train, preds_train)}\")\n",
    "print(f\"test: {accuracy_score(classes_test, preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
